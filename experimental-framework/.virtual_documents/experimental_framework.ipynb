import easyocr
import cv2
from PIL import Image

import os


#Remove dodgy images
data_dir = 'data'
image_exts = ['jpeg', 'jpg', 'bmp', 'png']

for image in os.listdir(data_dir):
    image_path = os.path.join(data_dir, image)
    try:
        img = cv2.imread(image_path)
        _, ext = os.path.splitext(image_path)
        ext = ext.lower().replace('.', '')
        if ext not in image_exts:
            print('Image not in ext list {}'.format(image_path))
            os.remove(image_path)
        #else :
            #print("it's ok")
    except Exception as e:
        print('Issue with image {}'.format(image_path))
        # os.remove(image_path)


import pandas as pd
import numpy as np 

from glob import glob 
from tqdm.notebook import tqdm 

import matplotlib.pyplot as plt 


img_fns = glob(data_dir + '/*')
#print(img_fns)


img_id = img_fns[0].split('\\')[-1].split('.')[0]


img = plt.imread(img_fns[0]); plt.imshow(img); plt.axis('off'); plt.show()
#plt.imshow(plt.imread(img_fns[0]))


from progressbar import ProgressBar

reader = easyocr.Reader(['en'], gpu = False)#create reader with english langage

dfs = []
pbar = ProgressBar()
for img in pbar(img_fns[:25]):
        result = reader.readtext(img)
    img_id = img.split('/')[-1].split('.')[0]
    img_df = pd.DataFrame(result, columns=['bbox','text','conf'])
    img_df['img_id'] = img_id
    dfs.append(img_df)
easyocr_df = pd.concat(dfs)


import keras_ocr


def plot(img_fn, easyocr_df):
    #img_id = img_fn.split('/')[-1].split('.')[0]
    #fig, axs = plt.subplots(1, 2, figsize=(15, 10))
    

    #easy_results = easyocr_df.query('img_id == @img_id')[['text','bbox']].values.tolist()
    #easy_results = [(x[0], np.array(x[1])) for x in easy_results]
    #keras_ocr.tools.drawAnnotations(plt.imread(img_fn), 
                                    #easy_results, ax=axs[0])
    #axs[0].set_title('easyocr results', fontsize=24)
    ##keras_results = kerasocr_df.query('img_id == @img_id')[['text','bbox']].values.tolist()
    ##keras_results = [(x[0], np.array(x[1])) for x in keras_results]
    ##keras_ocr.tools.drawAnnotations(plt.imread(img_fn), 
                                    #keras_results, ax=axs[1])
    ##axs[1].set_title('keras_ocr results', fontsize=24)
    img_id = img_fn.split('/')[-1].split('.')[0]
    fig, ax = plt.subplots(figsize=(15, 10))  # Create one sub trame

    easy_results = easyocr_df.query('img_id == @img_id')[['text','bbox']].values.tolist()
    easy_results = [(x[0], np.array(x[1])) for x in easy_results]
    keras_ocr.tools.drawAnnotations(plt.imread(img_fn),
                                    easy_results, ax=ax) #color=(0, 255, 0) #line_thickness=1 # Affiche l'image et les résultats de reconnaissance de texte dans la sous-trame
    ax.set_title(img_id + 'result', fontsize=24)
    
    plt.show()


'''
def plot(img_fn, easyocr_df, threshold=0.25):
    img_id = img_fn.split('/')[-1].split('.')[0]
    fig, ax = plt.subplots(figsize=(15, 10))  # Create one sub trame

    # Filter results by confidence score
    easy_results = easyocr_df.query('img_id == @img_id and conf > @threshold')[['text','bbox']].values.tolist()
    easy_results = [(x[0], np.array(x[1])) for x in easy_results]

    # Draw annotations on image
    keras_ocr.tools.drawAnnotations(plt.imread(img_fn),
                                    easy_results, ax=ax)  # Affiche l'image et les résultats de reconnaissance de texte dans la sous-trame
    ax.set_title(img_id + ' result', fontsize=24)

    plt.show()
    '''


# Loop over results
for img_fn in img_fns[:25]:
    plot(img_fn, easyocr_df)  
'''
for img_fn in img_fns[:25]:
    plot(img_fn, easyocr_df, threshold=0.25)  
'''


# Loop over results
for img_fn in img_fns[:25]:
    plot(img_fn, easyocr_df)
'''
# Loop over results
threshold = 0.25

for img_fn in img_fns[:25]:
    # get trust value for actual image 
    img_id = img_fn.split('/')[-1].split('.')[0]
    conf = easyocr_df.query('img_id == @img_id')['conf'].iloc[0]

    # verify if trust value is superior than threshold
    if conf > threshold:
        plot(img_fn, easyocr_df)
'''











reader = easyocr.Reader(['en'], gpu=False)
result = reader.readtext('de.png')

#for (bbox, text, prob) in result:
  #print(text)

print(result)




# Charger l'image
image = cv2.imread('de.png')



# Obtenir les résultats de la détection de texte
result = reader.readtext('de.png')

# Dessiner les rectangles verts autour des zones de texte détectées
for detection in result:
    bbox = detection[0]
    cv2.rectangle(image, (bbox[0][0], bbox[0][1]), (bbox[2][0], bbox[2][1]), (0, 255, 0), 2)

# Enregistrer l'image avec les rectangles dessinés
cv2.imwrite('text_detection_output.png', image)



