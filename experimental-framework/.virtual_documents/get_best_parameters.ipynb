import imutils
import easyocr
import cv2
import numpy as np
import matplotlib.pyplot as plt 




#have list of images path
from glob import glob 
data_dir = 'data'
img_fns = glob(data_dir + '/*')
#print(img_fns)





img = cv2.imread(data_dir + '/image002.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
plt.imshow(cv2.cvtColor(gray, cv2.COLOR_BGR2RGB))
plt.axis('off')


bfilter = cv2.bilateralFilter(gray, 11, 17, 17) #Noise reduction
#edged = cv2.Canny(bfilter, 30, 200) #Edge detection
#ok = cv2.cvtColor(gray, cv2.COLOR_BGR2RGB)
#plt.imshow(cv2.cvtColor(edged, cv2.COLOR_BGR2RGB))
#plt.imshow(ok)


reader = easyocr.Reader(['en'], gpu = False)#create reader with english langage
result_1 = reader.readtext(bfilter, decoder='beamsearch') #img de base avec bfilter et beamsearch
result_2 = reader.readtext(bfilter, decoder='wordbeamsearch')# img de base avec bfilter et wordbeamsearch
result_3 = reader.readtext(img) # img de base
print(result_1)
print('----------------------------------------------------')
print('----------------------------------------------------')
print(result_2)
print('----------------------------------------------------')
print('----------------------------------------------------')
print(result_3)





from colorthief import ColorThief


def is_background_darkened(img_path):
    ct = ColorThief(img_path)
    dominent_color = ct.get_color(quality=1)
    #print(dominent_color)
    #plt.imshow([dominent_color])
    #plt.show()

    # Convertir la couleur en niveaux de gris
    gray = np.dot(dominent_color[0:3], [0.299, 0.587, 0.114])

    # Déterminer si la couleur du background est claire ou foncée
    if gray > 128:
        return False
    else:
        return True

#path = 'test/image001.jpg'
#result = is_background_darkened(path)
#print(result)





def process_not_darkened_background(img_path):
    # Lire l'image
    img = cv2.imread(img_path)
    
    # Convertir l'image en niveaux de gris
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    # Appliquer le seuillage
    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)
    
    # Inverser les couleurs
    inverted = cv2.bitwise_not(thresh)
    
    # Afficher l'image résultante
    #plt.imshow(inverted)
    return(inverted)


img_path = 'test/image002.jpg'

img_with_not_dk_fn = process_not_darkened_background(img_path)

reader = easyocr.Reader(['en'], gpu = False)#create reader with english langage
result_1 = reader.readtext(img_with_not_dk_fn, decoder='beamsearch') #img de base avec bfilter et beamsearch
result_2 = reader.readtext(bfilter, decoder='wordbeamsearch')# img de base avec bfilter et wordbeamsearch


print(result_1)
print(result_2)





def process_background_darkened(img_path):
    # Charger l'image
    img = cv2.imread(img_path)
        
    # Convertir l'image en niveaux de gris
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
    # Appliquer le seuillage inversé
    _, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY_INV)
        
    # Inverser les couleurs
    invertedd = cv2.bitwise_not(thresh)
        
    # Afficher l'image originale et l'image inversée
    #cv2.imshow('Original Image', img)
    #plt.imshow(invertedd)
    return invertedd


img_path = 'test/image001.jpg'

img_with_dk_fn = process_background_darkened(img_path)

reader = easyocr.Reader(['en'], gpu = False)#create reader with english langage
result_1 = reader.readtext(img_with_dk_fn, decoder='beamsearch') #img de base avec bfilter et beamsearch
result_2 = reader.readtext(img_with_dk_fn, decoder='wordbeamsearch')# img de base avec bfilter et wordbeamsearch

print(result_1)
print('-----------------------------------------------------------------------')
print(result_2)





def is_low_contrast(img_path):
    # load image as YUV (or YCbCR) and select Y (intensity)
    # or convert to grayscale, which should be the same.
    # Alternately, use L (luminance) from LAB.
    img = cv2.imread(img_path)
    Y = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)[:,:,0]
    
    # compute min and max of Y
    min = np.min(Y)
    max = np.max(Y)
    
    # compute contrast
    contrast = (max-min)/(max+min)
    if contrast < 0.5 :
        return True 
    else :
        return False

    #print(min,max,contrast)
    #plt.imshow(img)
        
#img_path = 'test/low2.png'
#print(is_low_contrast(img_path))





def ajust_low_contrast(img_path):
    #imgo = cv2.imread('test/low2.png')
    
    # Charger l'image
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    
    # Appliquer l'égalisation d'histogramme
    img_equalized = cv2.equalizeHist(img)
    '''
    # Afficher les images d'origine et égalisée côte à côte
    fig, axs = plt.subplots(1, 2, figsize=(10, 5))
    axs[0].imshow(imgo)
    axs[0].set_title('Original Image')
    axs[1].imshow(img_equalized, cmap='gray')
    axs[1].set_title('Equalized Image')
    plt.show()
    '''
    return img_equalized





#fonction to get saturation
import os
def get_saturation(img_path):
    img = cv2.imread(img_path)
    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    saturation = img_hsv[:, :, 1].mean()
    return saturation                         


def ajust_hight_saturation(img_path):
    tab = []
    # Charger l'image
    img = cv2.imread(img_path)
    
    # Convertir l'image en niveaux de gris
    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    tab.append(gray_image)
    # Afficher l'image en niveaux de gris
    #plt.imshow(gray_image)
    
    cv2.imwrite('img_to_process/gray_image.png', gray_image)
    tab.append('img_to_process/gray_image.png')
    return tab


img_path = 'data/image034.jpg'

img = cv2.imread(img_path)
new_img = ajust_hight_saturation(img_path)[0]
best = process_background_darkened(ajust_hight_saturation(img_path)[1])
reader = easyocr.Reader(['en'], gpu = False)#create reader with english langage
result_1 = reader.readtext(img, decoder='beamsearch') #img de base 
result_2 = reader.readtext(new_img, decoder='beamsearch')# img en appliquant un filtre pour saturation
result_3 = reader.readtext(best, decoder='beamsearch')# img en appliquant un filtre pour saturation + background foncé
print(result_1)
print('-----------------------------------------------------------------------')
print(result_2)
print('-----------------------------------------------------------------------')
print(result_3)


img_path = 'img_to_process/gray_image.png'

result_img = process_background_darkened(img_path)

plt.imshow(result_img)







import os
import math

def get_threshold_saturation(data_dir):
    saturation_values = []
    #data_dir = 'data'
    image_exts = ['jpeg', 'jpg', 'bmp', 'png']
    
    for image in os.listdir(data_dir):
        if image.lower().split('.')[-1] in image_exts:
            image_path = os.path.join(data_dir, image)
            img = cv2.imread(image_path)
                
            if img is not None:
                img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
                saturation = img_hsv[:, :, 1].mean()
                saturation_values.append(saturation)
            else:
                print(f"Failed to read {image_path}")
    # Calcul de la moyenne
    mean_saturation = sum(saturation_values) / len(saturation_values)

    # Calcul de l'écart-type
    std_saturation = math.sqrt(sum([(x - mean_saturation) ** 2 for x in saturation_values]) / len(saturation_values))

    # Définition du seuil
    threshold = mean_saturation + std_saturation
    return threshold



#apply fonction to get saturation against 5 dataset
dataset = ['data','data1','data2','data3','data4']
sat = []
for data in dataset:
    sat.append(get_threshold_saturation(data))

#the average of these return will be our threshold
threshold_saturation = sum(sat) / len(sat)
print(threshold_saturation)





#fonction who apply filters to image in repertory, create,and stocke this image and in other repertory 

def improve_image(img_path):
    # Extract file name of img_path
    file_name = os.path.basename(img_path)
    # build new file name with result before the extension
    file_name_result = file_name.split('.')[0] + '_result.png'
    # build new path
    new_img_path = os.path.join('img_to_process', file_name_result)
    
    if get_saturation(img_path) > 127.23:
        if is_background_darkened(img_path):
            img = process_background_darkened(img_path)
            cv2.imwrite(new_img_path, img)
        else : 
            img = process_not_darkened_background(img_path)
            cv2.imwrite(new_img_path, img)
    else : 
        if is_low_contrast(img_path):
            img = ajust_low_contrast(img_path)
            cv2.imwrite(new_img_path, img)
        else :
            if is_background_darkened(img_path):
                img = process_background_darkened(img_path)
                cv2.imwrite(new_img_path, img)
            else : 
                img = process_not_darkened_background(img_path)
                cv2.imwrite(new_img_path, img) 


reader = easyocr.Reader(['en'], gpu=False)
img_pathhh = 'test/de2.jpg'
improve_image(img_pathhh)

img_path_result = 'img_to_process/de2_result.png'


imggg = cv2.imread(img_pathhh)
img2 = cv2.imread(img_path_result)
result = reader.readtext(imggg)
result2 = reader.readtext(img2)


plt.imshow(imggg)
print(result)
print("--------------------")
print(result2)   

    


# Créer deux listes vides
liste1 = []
liste2 = []

# Ajouter les mots de result à la première liste
for mot in result:
    liste1.append(mot[1])

# Ajouter les mots de result2 à la deuxième liste
for mot in result2:
    liste2.append(mot[1])

# Afficher les deux listes
print(liste1)
print("--------------------")
print(liste2)






data_dir = 'data'


for image in os.listdir(data_dir):
    ok = os.path.join(data_dir, image)
    img_path = f"'{ok}'"
    print(img_path)
improve_image('data\image001.jpg')
    
        



