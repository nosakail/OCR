import imutils
import easyocr
import cv2
import numpy as np
import matplotlib.pyplot as plt 




#have list of images path
from glob import glob 
data_dir = 'test'
img_fns = glob(data_dir + '/*')
#print(img_fns)





img = cv2.imread(data_dir + '/image002.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
plt.imshow(cv2.cvtColor(gray, cv2.COLOR_BGR2RGB))
plt.axis('off')


bfilter = cv2.bilateralFilter(gray, 11, 17, 17) #Noise reduction
#edged = cv2.Canny(bfilter, 30, 200) #Edge detection
#ok = cv2.cvtColor(gray, cv2.COLOR_BGR2RGB)
#plt.imshow(cv2.cvtColor(edged, cv2.COLOR_BGR2RGB))
#plt.imshow(ok)


reader = easyocr.Reader(['en'], gpu = False)#create reader with english langage
result_1 = reader.readtext(bfilter, decoder='beamsearch') #img de base avec bfilter et beamsearch
result_2 = reader.readtext(bfilter, decoder='wordbeamsearch')# img de base avec bfilter et wordbeamsearch
result_3 = reader.readtext(img) # img de base
print(result_1)
print('----------------------------------------------------')
print('----------------------------------------------------')
print(result_2)
print('----------------------------------------------------')
print('----------------------------------------------------')
print(result_3)





from colorthief import ColorThief


def is_background_darkened(img_path):
    ct = ColorThief(img_path)
    dominent_color = ct.get_color(quality=1)
    #print(dominent_color)
    #plt.imshow([dominent_color])
    #plt.show()

    # Convertir la couleur en niveaux de gris
    gray = np.dot(dominent_color[0:3], [0.299, 0.587, 0.114])

    # Déterminer si la couleur du background est claire ou foncée
    if gray > 128:
        return False
    else:
        return True

#path = 'test/image001.jpg'
#result = is_background_darkened(path)
#print(result)





# Lire l'image
img = cv2.imread('test/image002.jpg')

# Convertir l'image en niveaux de gris
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# Appliquer le seuillage
_, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)

# Inverser les couleurs
inverted = cv2.bitwise_not(thresh)

# Afficher l'image résultante
plt.imshow(inverted)


reader = easyocr.Reader(['en'], gpu = False)#create reader with english langage
result_1 = reader.readtext(inverted, decoder='beamsearch') #img de base avec bfilter et beamsearch
result_2 = reader.readtext(bfilter, decoder='wordbeamsearch')# img de base avec bfilter et wordbeamsearch


print(result_1)
print(result_2)





# Charger l'image
img = cv2.imread('test/image001.jpg')

# Convertir l'image en niveaux de gris
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# Appliquer le seuillage inversé
_, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY_INV)

# Inverser les couleurs
invertedd = cv2.bitwise_not(thresh)

# Afficher l'image originale et l'image inversée
#cv2.imshow('Original Image', img)
plt.imshow(invertedd)



reader = easyocr.Reader(['en'], gpu = False)#create reader with english langage
result_1 = reader.readtext(invertedd, decoder='beamsearch') #img de base avec bfilter et beamsearch
result_2 = reader.readtext(invertedd, decoder='wordbeamsearch')# img de base avec bfilter et wordbeamsearch

print(result_1)
print('-----------------------------------------------------------------------')
print(result_2)





# load image as YUV (or YCbCR) and select Y (intensity)
# or convert to grayscale, which should be the same.
# Alternately, use L (luminance) from LAB.
img = cv2.imread("test/low2.png")
Y = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)[:,:,0]

# compute min and max of Y
min = np.min(Y)
max = np.max(Y)

# compute contrast
contrast = (max-min)/(max+min)
print(min,max,contrast)
plt.imshow(img)



