{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3553ed17-790e-4316-aa03-c24dfbf76aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yassi\\Desktop\\OCR\\librairies-test\\librairiestest\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "model_version = \"microsoft/trocr-base-printed\"\n",
    "processor = TrOCRProcessor.from_pretrained(model_version)\n",
    "model = VisionEncoderDecoderModel.from_pretrained(model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb21e104-b9be-49b5-a45b-22a09106806e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yassi\\Desktop\\OCR\\librairies-test\\librairiestest\\Lib\\site-packages\\transformers\\generation\\utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:  SR865\n"
     ]
    }
   ],
   "source": [
    "image = Image.open(\"lowc.jpg\").convert(\"RGB\")\n",
    "pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "start_time = time.time()  \n",
    "generated_ids = model.generate(pixel_values)\n",
    "end_time = time.time()  \n",
    "extract_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "processing_time = end_time - start_time\n",
    "print('output: ',extract_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4695e77c-9428-46e6-938f-eacf31be6dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.880062580108643\n"
     ]
    }
   ],
   "source": [
    "print(processing_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55375eee-5c5b-4faa-a80e-e88a8a65f914",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\yassi\\\\Desktop\\\\OCR\\\\librairies-test\\\\TrOCR\\\\lowc_crop.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m crp_image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlowc_crop.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\OCR\\librairies-test\\librairiestest\\Lib\\site-packages\\PIL\\Image.py:3277\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3274\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[0;32m   3276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3277\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3278\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3280\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\yassi\\\\Desktop\\\\OCR\\\\librairies-test\\\\TrOCR\\\\lowc_crop.jpg'"
     ]
    }
   ],
   "source": [
    "crp_image = Image.open(\"lowc_crop.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fb6e4e-f6fd-479e-9b6b-761b16f6a8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_values = processor(crp_image, return_tensors=\"pt\").pixel_values\n",
    "start_time = time.time()  # Démarrer le chronomètre\n",
    "generated_ids = model.generate(pixel_values)\n",
    "end_time = time.time()  # Arrêter le chronomètre\n",
    "extract_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "processing_time1 = end_time - start_time\n",
    "print('Output from cropped image:', extract_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1314ed1-af48-4b49-8b5b-4f5391084288",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(processing_time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5116403f-c2b6-460a-9ed3-d005e03be44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m pixel_values \u001b[38;5;241m=\u001b[39m processor(image, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mpixel_values\n\u001b[1;32m---> 33\u001b[0m start_time \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[38;5;241m.\u001b[39mtime() \n\u001b[0;32m     34\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(pixel_values)\n\u001b[0;32m     35\u001b[0m extract_text \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mbatch_decode(generated_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image, ImageDraw\n",
    "import pytesseract\n",
    "\n",
    "# Configuration de Tesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\yassi\\AppData\\Local\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Chargement du modèle TrOCR\n",
    "model_version = \"microsoft/trocr-base-printed\"\n",
    "processor = TrOCRProcessor.from_pretrained(model_version)\n",
    "model = VisionEncoderDecoderModel.from_pretrained(model_version)\n",
    "\n",
    "# Fonction pour dessiner les boîtes englobantes avec pytesseract\n",
    "def draw_boxes(image_path, output_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    width, height = image.size\n",
    "    \n",
    "    # Obtenir les boîtes englobantes des caractères avec pytesseract\n",
    "    boxes = pytesseract.image_to_boxes(image)\n",
    "    for b in boxes.splitlines():\n",
    "        b = b.split(' ')\n",
    "        x1, y2, x2, y1 = int(b[1]), height - int(b[2]), int(b[3]), height - int(b[4])\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=(0, 255, 0), width=2)\n",
    "    \n",
    "    image.save(output_path)\n",
    "    image.show()\n",
    "\n",
    "# Analyser et extraire le texte avec TrOCR\n",
    "image_path = \"lowc.jpg\"\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "start_time = time.time() \n",
    "generated_ids = model.generate(pixel_values)\n",
    "extract_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "#print('Output:', extract_text)\n",
    "\n",
    "# Dessiner les boîtes englobantes sur l'image originale\n",
    "draw_boxes(image_path, \"lowc_result_with_boxes.png\")\n",
    "\n",
    "end_time = time.time()\n",
    "processing_time = end_time - start_time\n",
    "'''\n",
    "# Analyser et extraire le texte à partir de l'image recadrée avec TrOCR\n",
    "crp_image_path = \"lowc_crop.jpg\"\n",
    "crp_image = Image.open(crp_image_path).convert(\"RGB\")\n",
    "pixel_values = processor(crp_image, return_tensors=\"pt\").pixel_values\n",
    "start_time1 = time.time() \n",
    "generated_ids = model.generate(pixel_values)\n",
    "extract_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "#print('Output from cropped image:', extract_text)\n",
    "\n",
    "# Dessiner les boîtes englobantes sur l'image recadrée\n",
    "draw_boxes(crp_image_path, \"lowc_result_crop_with_boxes.png\")\n",
    "end_time1 = time.time()\n",
    "processing_time1 = end_time1 - start_time1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e26124-dd9b-4d29-9160-7821ae6b82e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(processing_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f46fbc0-c3b7-4695-aae3-f18a05bb94db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(processing_time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5855b3bf-efe2-4c81-860f-58f20025e2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "librairiestest",
   "language": "python",
   "name": "librairiestest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
